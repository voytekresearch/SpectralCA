{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sys\n",
    "# locate your spectralCV so we have scv_funcs to use\n",
    "sys.path.append('/Users/ldliao/Research/Projects/spectralCA/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io as io\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import mne\n",
    "\n",
    "from sca import sca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trial_info(cue_sig, move_sig, L_win=1000, L_lag=2000, alpha=0.95):\n",
    "    # stim_info vector: [trial onset, movement onset, trial type, RT, premove duration, move duration]\n",
    "    trial_init = np.where(np.diff((cue_sig>0).astype(int))==1)[0]+1\n",
    "    move_init = np.where(np.diff((move_sig>0).astype(int))==1)[0]+1 \n",
    "    trial_info = []\n",
    "    for i, tr_onset in enumerate(trial_init):\n",
    "        # pre-movement length\n",
    "        L_premove = np.sum(move_sig[tr_onset-L_win:tr_onset]<=0)    \n",
    "        # find corresponding movement onset time\n",
    "        try:\n",
    "            # if this fails, it means there was no response on the last trial\n",
    "            mv_onset = move_init[np.where(move_init>tr_onset)[0][0]]        \n",
    "            L_move = np.sum(move_sig[mv_onset:mv_onset+L_win]>0)\n",
    "            # if 3 conditions are satisfied, add trial\n",
    "            if L_premove/L_win>alpha and L_move/L_win>alpha and (mv_onset-tr_onset)<L_lag:\n",
    "                RT = mv_onset-tr_onset\n",
    "                trial_info.append([tr_onset, mv_onset, move_sig[mv_onset], RT, L_premove, L_move])\n",
    "        except:\n",
    "            print('Skipped last trial.')\n",
    "    return np.array(trial_info)\n",
    "\n",
    "def sca_kjm(data_path, subj, fs, analysis_param):\n",
    "    # load data & trial info\n",
    "    stim_info = io.loadmat(data_path+'data/'+subj+'/'+subj+'_stim.mat', squeeze_me=True)\n",
    "    data = io.loadmat(data_path+'data/'+subj+'/'+subj+'_fingerflex.mat', squeeze_me=True)\n",
    "    ecog = data['data'].T\n",
    "    \n",
    "    # set parameters\n",
    "    win_len = int(fs)\n",
    "    num_chan = ecog.shape[0]\n",
    "    max_freq = analysis_param['max_freq']\n",
    "    \n",
    "    # sort out trial info\n",
    "    trial_info = get_trial_info(data['cue'], stim_info['stim'], L_win=win_len, L_lag=1500, alpha=0.9)\n",
    "    num_trials = trial_info.shape[0]\n",
    "    print('%i included trials.'%num_trials)\n",
    "        \n",
    "    if num_trials>20:\n",
    "        # pre-initialize arrays\n",
    "        psd_precomp = np.zeros((num_chan, max_freq, num_trials, 2))\n",
    "\n",
    "        # precompute trial PSDs\n",
    "        for tr in range(num_trials):\n",
    "            tr_onset = trial_info[tr,0]\n",
    "            mv_onset = trial_info[tr,1]\n",
    "            # pre-movement\n",
    "            f_axis, t_axis, spg = sp.signal.spectrogram(ecog[:,tr_onset-win_len:tr_onset],fs=fs,nperseg=win_len)\n",
    "            p_ = np.mean(spg,axis=-1)      \n",
    "            psd_precomp[:,:,tr,0] = p_[:,:max_freq]\n",
    "            # movement\n",
    "            f_axis, t_axis, spg = sp.signal.spectrogram(ecog[:,mv_onset:mv_onset+win_len],fs=fs,nperseg=win_len)\n",
    "            p_ = np.mean(spg,axis=-1)   \n",
    "            psd_precomp[:,:,tr,1] = p_[:,:max_freq]\n",
    "\n",
    "        sca_all = []\n",
    "        for i in range(2):\n",
    "            mov_sca = sca.SCA(analysis_param)\n",
    "            mov_sca.populate_fourier_data(psd_precomp[:,:,:,i], fs, f_axis)\n",
    "            mov_sca.compute_psd()\n",
    "            mov_sca.compute_scv()\n",
    "            sca_all.append(mov_sca)\n",
    "\n",
    "        # return the pre- and during-movement sca data, and trial info\n",
    "        return sca_all, trial_info\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define data folder\n",
    "data_path = '/Users/ldliao/Research/Data/ECoG_KJM/digit/'\n",
    "saveout_path = '../results/kjm_digits/'\n",
    "save_files = ['pre','move','whole']\n",
    "subjs = ['bp', 'cc', 'ht', 'jc', 'jp', 'mv', 'wc', 'wm', 'zt']\n",
    "\n",
    "# electrode location\n",
    "elec_def = [('0', 'dorsal_M1'),\n",
    "            ('1', 'dorsal_S1'),\n",
    "            ('2', 'ventral_S1+M1'),\n",
    "            ('3', 'frontal_(non-R)'),\n",
    "            ('4', 'parietal_(non-R)'),\n",
    "            ('5', 'temporal'),\n",
    "            ('6', 'occipital')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bp\n",
      "103 included trials.\n",
      "Computing exponential KS test...\n",
      "0\n",
      "1\n",
      "2\n",
      "cc\n",
      "63 included trials.\n",
      "Computing exponential KS test...\n",
      "0\n",
      "1\n",
      "2\n",
      "ht\n",
      "84 included trials.\n",
      "Computing exponential KS test...\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-09083fb4ea78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchan_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chan_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melec_def\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_freq_corr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0;31m# save out sca\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_spec_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubj_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msave_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.npz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_spg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Projects/spectralCA/sca/sca.py\u001b[0m in \u001b[0;36mcross_freq_corr\u001b[0;34m(self, log_pow_vals)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreq_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                     pow_corrmat[chan][row][col], pow_pvmat[chan][row][col] = pearsonr(pow_vals[chan][row],\n\u001b[0;32m--> 174\u001b[0;31m                                                                                       pow_vals[chan][col])\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow_corrmat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpow_corrmat\u001b[0m \u001b[0;31m# correlation matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3005\u001b[0m     \u001b[0mmx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3006\u001b[0m     \u001b[0mmy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3007\u001b[0;31m     \u001b[0mxm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mym\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3008\u001b[0m     \u001b[0mr_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3009\u001b[0m     \u001b[0mr_den\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sum_of_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_sum_of_squares\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mym\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fs = 1000.\n",
    "# sca params\n",
    "analysis_param = {'nperseg': 1000,\n",
    "                 'noverlap': 0,\n",
    "                 'spg_outlierpct': 2.,\n",
    "                 'max_freq':200}\n",
    "\n",
    "for subj in subjs:\n",
    "    print(subj)\n",
    "    # get the trial-separated sca\n",
    "    sca_all, trial_info = sca_kjm(data_path,subj,fs,analysis_param)\n",
    "    if sca_all is not None:\n",
    "        # get sca for whole recording\n",
    "        data = io.loadmat(data_path+'data/'+subj+'/'+subj+'_fingerflex.mat', squeeze_me=True)    \n",
    "        sca_all.append(sca.SCA(analysis_param))\n",
    "        sca_all[-1].populate_ts_data(data['data'].T, fs)\n",
    "        sca_all[-1].compute_all_spectral()\n",
    "\n",
    "        # make dir\n",
    "        subj_path = saveout_path+subj+'/'\n",
    "        if not os.path.isdir(subj_path):\n",
    "            os.mkdir(subj_path)\n",
    "\n",
    "        print('Computing exponential KS test...')\n",
    "        for ind, sc in enumerate(sca_all):\n",
    "            # compute fit\n",
    "            sc.compute_KS_expfit()\n",
    "            # save channel labels\n",
    "            sc.chan_labels = ['chan_' + key + '_' + val for (key, val) in elec_def]\n",
    "#             print(ind)\n",
    "#             sc.cross_freq_corr()\n",
    "            # save out sca         \n",
    "            sc.save_spec_vars(subj_path+save_files[ind]+'.npz', save_spg=True)\n",
    "\n",
    "        # save trial info and plot contrast\n",
    "        np.savez(subj_path+'trial_info.npz', trial_info=trial_info, elec_regions=data['elec_regions'])\n",
    "    else:\n",
    "        print('Skipped subject.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/voytek/lib/python3.6/site-packages/bids/layout/layout.py:665: UserWarning: In pybids 0.9.0, the 'extensions' filter was deprecated in favor of 'extension'. The former will stop working in 0.11.0.\n",
      "  warnings.warn(\"In pybids 0.9.0, the 'extensions' filter was \"\n"
     ]
    }
   ],
   "source": [
    "import bids\n",
    "\n",
    "\n",
    "subj, sess, run = '01', '01', 1\n",
    "layout = bids.layout.BIDSLayout('/Users/ldliao/Research/Data/Hermes_VCECoG/')\n",
    "f_raw = layout.get(return_type='object', suffix='ieeg', subject=subj, session=sess, run=run, extensions='.vhdr')[0]\n",
    "f_events = layout.get(return_type='object', suffix='events', subject=subj, session=sess, run=run)[0]\n",
    "f_channels = layout.get(return_type='object', suffix='channels', subject=subj, session=sess, run=run)[0]\n",
    "f_elec = layout.get(return_type='object', suffix='electrodes', subject=subj, session=sess)[0]\n",
    "\n",
    "events = pd.read_csv(f_events.path, delimiter='\\t')\n",
    "chan_info = pd.read_csv(f_channels.path, delimiter='\\t')\n",
    "elec_loc = pd.read_csv(f_elec.path, delimiter='\\t').apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ECGChannelCount': 0,\n",
       " 'ECOGChannelCount': 118,\n",
       " 'EEGChannelCount': 0,\n",
       " 'EMGChannelCount': 0,\n",
       " 'EOGChannelCount': 0,\n",
       " 'ElectrodeManufacturer': 'AdTech',\n",
       " 'EpochLength': 0,\n",
       " 'HardwareFilters': ['highpass', '0.5', 'lowpass', '300'],\n",
       " 'InstitutionAddress': '300 Pasteur Dr, Stanford, CA 94305',\n",
       " 'InstitutionName': 'Stanford Hospital and Clinics',\n",
       " 'Instructions': 'look at the dot in the center of the screen and press the button when it changes color',\n",
       " 'Manufacturer': 'Tucker Davis Technologies',\n",
       " 'MiscChannelCount': 0,\n",
       " 'PowerLineFrequency': 60,\n",
       " 'RecordingDuration': 233.639,\n",
       " 'RecordingType': 'continuous',\n",
       " 'SEEGChannelCount': 0,\n",
       " 'SamplingFrequency': 3051.76,\n",
       " 'SoftwareFilters': 'n/a',\n",
       " 'TaskDescription': 'visual gratings and noise patterns',\n",
       " 'TaskName': 'visual',\n",
       " 'TriggerChannelCount': 0,\n",
       " 'iEEGPlacementScheme': 'right occipital temporal surface',\n",
       " 'iEEGReferenceScheme': 'intracranial channel not included with data'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layout.get_metadata(f_raw.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/ldliao/Research/Data/Hermes_VCECoG/sub-01/ses-01/ieeg/sub-01_ses-01_task-visual_run-01_ieeg.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 713009  =      0.000 ...   233.620 secs...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'strip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-0383dea3c3c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mraw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_raw_brainvision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/io/brainvision/brainvision.py\u001b[0m in \u001b[0;36mread_raw_brainvision\u001b[0;34m(vhdr_fname, montage, eog, misc, scale, preload, stim_channel, verbose)\u001b[0m\n\u001b[1;32m    831\u001b[0m     return RawBrainVision(vhdr_fname=vhdr_fname, montage=montage, eog=eog,\n\u001b[1;32m    832\u001b[0m                           \u001b[0mmisc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                           stim_channel=stim_channel, verbose=verbose)\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m</anaconda3/envs/voytek/lib/python3.6/site-packages/mne/externals/decorator.py:decorator-gen-146>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vhdr_fname, montage, eog, misc, scale, preload, stim_channel, verbose)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/utils/_logging.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0muse_log_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m     return FunctionMaker.create(\n\u001b[1;32m     91\u001b[0m         \u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'return decfunc(%(signature)s)'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/io/brainvision/brainvision.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vhdr_fname, montage, eog, misc, scale, preload, stim_channel, verbose)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Get annotations from vmrk file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mannots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmrk_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sfreq'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_annotations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/annotations.py\u001b[0m in \u001b[0;36mread_annotations\u001b[0;34m(fname, sfreq, uint16_codec)\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vmrk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m         \u001b[0mannotations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_annotations_brainvision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msfreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/io/brainvision/brainvision.py\u001b[0m in \u001b[0;36m_read_annotations_brainvision\u001b[0;34m(fname, sfreq)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \"\"\"\n\u001b[1;32m    260\u001b[0m     \u001b[0monset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_vmrk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 261\u001b[0;31m     \u001b[0morig_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate_str\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_str_to_meas_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msfreq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/voytek/lib/python3.6/site-packages/mne/io/brainvision/brainvision.py\u001b[0m in \u001b[0;36m_str_to_meas_date\u001b[0;34m(date_str)\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_str_to_meas_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m     \u001b[0mdate_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdate_str\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'00000000000000000000'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'strip'"
     ]
    }
   ],
   "source": [
    "raw = mne.io.read_raw_brainvision(f_raw.path, preload=True)\n",
    "raw.info\n",
    "data, t = raw[:,:]\n",
    "data = data[:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
